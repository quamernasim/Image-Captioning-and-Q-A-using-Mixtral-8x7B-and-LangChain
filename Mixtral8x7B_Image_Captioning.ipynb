{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "#############################\n",
        "# Install all dependencies\n",
        "#############################\n",
        "\n",
        "%pip install langchain==0.0.352 \\\n",
        "             re==2.2.1 \\\n",
        "             pydantic==2.5.3 \\\n",
        "             Pillow==10.0.1 \\\n",
        "             requests==2.31.0 \\\n",
        "             transformers==4.36.2 \\\n",
        "             torch==2.1.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "####################################################################\n",
        "# Define the model name and path for both the model (LLM and BLIP)\n",
        "####################################################################\n",
        "\n",
        "BLIP_MODEL_NAME = 'Salesforce/blip-image-captioning-large'\n",
        "MODEL_NAME = 'mistralai/Mixtral-8x7B-Instruct-v0.1'\n",
        "\n",
        "# Make sure the model path is correct for your system!\n",
        "MODEL_PATH = 'mixtral-8x7b-instruct-v0.1.Q5_0.gguf'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "#########################################################################################\n",
        "# Load the image captioning model\n",
        "# For the purposes of this blog post, we'll be using BLIP to caption images.\n",
        "#########################################################################################\n",
        "\n",
        "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
        "\n",
        "blip_processor = BlipProcessor.from_pretrained(BLIP_MODEL_NAME)\n",
        "blip_model = BlipForConditionalGeneration.from_pretrained(BLIP_MODEL_NAME)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Xq99mK7YXTuY"
      },
      "outputs": [],
      "source": [
        "##########################################################################################\n",
        "# We need to define the tool that will be used to generate the image caption.\n",
        "# This tool will be used by the agent to generate the image caption.\n",
        "##########################################################################################\n",
        "\n",
        "import requests\n",
        "from PIL import Image\n",
        "from langchain.tools import tool\n",
        "from pydantic.v1 import BaseModel, Field\n",
        "\n",
        "class ImageCaptionerInput(BaseModel):\n",
        "    image_url: str = Field(description=\"URL of the image that is to be described\")\n",
        "\n",
        "@tool(\"image_captioner\", return_direct=True, args_schema=ImageCaptionerInput)\n",
        "def image_captioner(image_url: str) -> str:\n",
        "    \"\"\"Provides information about the image\"\"\"\n",
        "    raw_image = Image.open(requests.get(image_url, stream=True).raw).convert('RGB')\n",
        "    inputs = blip_processor(raw_image, return_tensors=\"pt\")\n",
        "    out = blip_model.generate(**inputs, max_new_tokens=512)\n",
        "    return blip_processor.decode(out[0], skip_special_tokens=True)\n",
        "\n",
        "tools = [image_captioner]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# def image_captioner__(image_url: str) -> str:\n",
        "#     \"\"\"Provides information about the image\"\"\"\n",
        "#     raw_image = Image.open(requests.get(image_url, stream=True).raw).convert('RGB')\n",
        "#     inputs = blip_processor(raw_image, return_tensors=\"pt\")\n",
        "#     out = blip_model.generate(**inputs, max_new_tokens=512)\n",
        "#     return blip_processor.decode(out[0], skip_special_tokens=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/deepkapha/.local/lib/python3.11/site-packages/langchain_core/utils/utils.py:159: UserWarning: WARNING! repetition_penalty is not default parameter.\n",
            "                repetition_penalty was transferred to model_kwargs.\n",
            "                Please confirm that repetition_penalty is what you intended.\n",
            "  warnings.warn(\n",
            "/home/deepkapha/.local/lib/python3.11/site-packages/langchain_core/utils/utils.py:159: UserWarning: WARNING! threads is not default parameter.\n",
            "                threads was transferred to model_kwargs.\n",
            "                Please confirm that threads is what you intended.\n",
            "  warnings.warn(\n",
            "/home/deepkapha/.local/lib/python3.11/site-packages/langchain_core/utils/utils.py:159: UserWarning: WARNING! stream is not default parameter.\n",
            "                stream was transferred to model_kwargs.\n",
            "                Please confirm that stream is what you intended.\n",
            "  warnings.warn(\n",
            "llama_model_loader: loaded meta data with 26 key-value pairs and 995 tensors from mixtral-8x7b-instruct-v0.1.Q5_0.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: - tensor    0:                token_embd.weight q5_0     [  4096, 32000,     1,     1 ]\n",
            "llama_model_loader: - tensor    1:          blk.0.ffn_gate.0.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor    2:          blk.0.ffn_down.0.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor    3:            blk.0.ffn_up.0.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor    4:          blk.0.ffn_gate.1.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor    5:          blk.0.ffn_down.1.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor    6:            blk.0.ffn_up.1.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor    7:          blk.0.ffn_gate.2.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor    8:          blk.0.ffn_down.2.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor    9:            blk.0.ffn_up.2.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor   10:          blk.0.ffn_gate.3.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor   11:          blk.0.ffn_down.3.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   12:            blk.0.ffn_up.3.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor   13:          blk.0.ffn_gate.4.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor   14:          blk.0.ffn_down.4.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   15:            blk.0.ffn_up.4.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor   16:          blk.0.ffn_gate.5.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor   17:          blk.0.ffn_down.5.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   18:            blk.0.ffn_up.5.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor   19:          blk.0.ffn_gate.6.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor   20:          blk.0.ffn_down.6.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   21:            blk.0.ffn_up.6.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor   22:          blk.0.ffn_gate.7.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor   23:          blk.0.ffn_down.7.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   24:            blk.0.ffn_up.7.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor   25:        blk.0.ffn_gate_inp.weight f16      [  4096,     8,     1,     1 ]\n",
            "llama_model_loader: - tensor   26:           blk.0.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   27:            blk.0.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   28:              blk.0.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor   29:         blk.0.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   30:              blk.0.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   31:              blk.0.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor   32:          blk.1.ffn_gate.0.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor   33:          blk.1.ffn_down.0.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   34:            blk.1.ffn_up.0.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor   35:          blk.1.ffn_gate.1.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor   36:          blk.1.ffn_down.1.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   37:            blk.1.ffn_up.1.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor   38:          blk.1.ffn_gate.2.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor   39:          blk.1.ffn_down.2.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   40:            blk.1.ffn_up.2.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor   41:          blk.1.ffn_gate.3.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor   42:          blk.1.ffn_down.3.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   43:            blk.1.ffn_up.3.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor   44:          blk.1.ffn_gate.4.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor   45:          blk.1.ffn_down.4.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   46:        blk.1.ffn_gate_inp.weight f16      [  4096,     8,     1,     1 ]\n",
            "llama_model_loader: - tensor   47:              blk.1.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor   48:         blk.1.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   49:              blk.1.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   50:              blk.1.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor   51:            blk.1.ffn_up.4.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor   52:          blk.1.ffn_gate.5.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor   53:          blk.1.ffn_down.5.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   54:            blk.1.ffn_up.5.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor   55:          blk.1.ffn_gate.6.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor   56:          blk.1.ffn_down.6.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   57:            blk.1.ffn_up.6.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor   58:          blk.1.ffn_gate.7.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor   59:          blk.1.ffn_down.7.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   60:            blk.1.ffn_up.7.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor   61:           blk.1.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   62:            blk.1.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   63:          blk.2.ffn_gate.0.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor   64:          blk.2.ffn_down.0.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   65:            blk.2.ffn_up.0.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor   66:          blk.2.ffn_gate.1.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor   67:          blk.2.ffn_down.1.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   68:            blk.2.ffn_up.1.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor   69:          blk.2.ffn_gate.2.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor   70:          blk.2.ffn_down.2.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   71:            blk.2.ffn_up.2.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor   72:          blk.2.ffn_gate.3.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor   73:          blk.2.ffn_down.3.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   74:            blk.2.ffn_up.3.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor   75:          blk.2.ffn_gate.4.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor   76:          blk.2.ffn_down.4.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   77:            blk.2.ffn_up.4.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor   78:          blk.2.ffn_gate.5.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor   79:          blk.2.ffn_down.5.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   80:            blk.2.ffn_up.5.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor   81:          blk.2.ffn_gate.6.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor   82:          blk.2.ffn_down.6.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   83:            blk.2.ffn_up.6.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor   84:          blk.2.ffn_gate.7.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor   85:          blk.2.ffn_down.7.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   86:            blk.2.ffn_up.7.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor   87:        blk.2.ffn_gate_inp.weight f16      [  4096,     8,     1,     1 ]\n",
            "llama_model_loader: - tensor   88:           blk.2.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   89:            blk.2.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor   90:              blk.2.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor   91:         blk.2.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   92:              blk.2.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   93:              blk.2.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor   94:          blk.3.ffn_gate.0.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor   95:          blk.3.ffn_down.0.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   96:            blk.3.ffn_up.0.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor   97:          blk.3.ffn_gate.1.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor   98:          blk.3.ffn_down.1.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor   99:            blk.3.ffn_up.1.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  100:          blk.3.ffn_gate.2.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  101:        blk.3.ffn_gate_inp.weight f16      [  4096,     8,     1,     1 ]\n",
            "llama_model_loader: - tensor  102:              blk.3.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  103:         blk.3.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  104:              blk.3.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  105:              blk.3.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  106:          blk.3.ffn_down.2.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  107:            blk.3.ffn_up.2.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  108:          blk.3.ffn_gate.3.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  109:          blk.3.ffn_down.3.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  110:            blk.3.ffn_up.3.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  111:          blk.3.ffn_gate.4.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  112:          blk.3.ffn_down.4.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  113:            blk.3.ffn_up.4.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  114:          blk.3.ffn_gate.5.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  115:          blk.3.ffn_down.5.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  116:            blk.3.ffn_up.5.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  117:          blk.3.ffn_gate.6.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  118:          blk.3.ffn_down.6.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  119:            blk.3.ffn_up.6.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  120:          blk.3.ffn_gate.7.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  121:          blk.3.ffn_down.7.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  122:            blk.3.ffn_up.7.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  123:           blk.3.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  124:            blk.3.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  125:          blk.4.ffn_gate.0.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  126:          blk.4.ffn_down.0.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  127:            blk.4.ffn_up.0.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  128:          blk.4.ffn_gate.1.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  129:          blk.4.ffn_down.1.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  130:            blk.4.ffn_up.1.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  131:          blk.4.ffn_gate.2.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  132:          blk.4.ffn_down.2.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  133:            blk.4.ffn_up.2.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  134:          blk.4.ffn_gate.3.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  135:          blk.4.ffn_down.3.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  136:            blk.4.ffn_up.3.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  137:          blk.4.ffn_gate.4.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  138:          blk.4.ffn_down.4.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  139:            blk.4.ffn_up.4.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  140:          blk.4.ffn_gate.5.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  141:          blk.4.ffn_down.5.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  142:            blk.4.ffn_up.5.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  143:          blk.4.ffn_gate.6.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  144:          blk.4.ffn_down.6.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  145:            blk.4.ffn_up.6.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  146:          blk.4.ffn_gate.7.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  147:          blk.4.ffn_down.7.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  148:            blk.4.ffn_up.7.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  149:        blk.4.ffn_gate_inp.weight f16      [  4096,     8,     1,     1 ]\n",
            "llama_model_loader: - tensor  150:           blk.4.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  151:            blk.4.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  152:              blk.4.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  153:         blk.4.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  154:              blk.4.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  155:              blk.4.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  156:        blk.5.ffn_gate_inp.weight f16      [  4096,     8,     1,     1 ]\n",
            "llama_model_loader: - tensor  157:              blk.5.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  158:         blk.5.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  159:              blk.5.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  160:              blk.5.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  161:          blk.5.ffn_gate.0.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  162:          blk.5.ffn_down.0.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  163:            blk.5.ffn_up.0.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  164:          blk.5.ffn_gate.1.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  165:          blk.5.ffn_down.1.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  166:            blk.5.ffn_up.1.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  167:          blk.5.ffn_gate.2.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  168:          blk.5.ffn_down.2.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  169:            blk.5.ffn_up.2.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  170:          blk.5.ffn_gate.3.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  171:          blk.5.ffn_down.3.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  172:            blk.5.ffn_up.3.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  173:          blk.5.ffn_gate.4.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  174:          blk.5.ffn_down.4.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  175:            blk.5.ffn_up.4.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  176:          blk.5.ffn_gate.5.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  177:          blk.5.ffn_down.5.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  178:            blk.5.ffn_up.5.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  179:          blk.5.ffn_gate.6.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  180:          blk.5.ffn_down.6.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  181:            blk.5.ffn_up.6.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  182:          blk.5.ffn_gate.7.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  183:          blk.5.ffn_down.7.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  184:            blk.5.ffn_up.7.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  185:           blk.5.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  186:            blk.5.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  187:          blk.6.ffn_gate.0.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  188:          blk.6.ffn_down.0.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  189:            blk.6.ffn_up.0.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  190:          blk.6.ffn_gate.1.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  191:          blk.6.ffn_down.1.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  192:            blk.6.ffn_up.1.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  193:          blk.6.ffn_gate.2.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  194:          blk.6.ffn_down.2.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  195:            blk.6.ffn_up.2.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  196:          blk.6.ffn_gate.3.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  197:          blk.6.ffn_down.3.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  198:            blk.6.ffn_up.3.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  199:          blk.6.ffn_gate.4.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  200:          blk.6.ffn_down.4.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  201:            blk.6.ffn_up.4.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  202:          blk.6.ffn_gate.5.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  203:          blk.6.ffn_down.5.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  204:        blk.6.ffn_gate_inp.weight f16      [  4096,     8,     1,     1 ]\n",
            "llama_model_loader: - tensor  205:              blk.6.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  206:         blk.6.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  207:              blk.6.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  208:              blk.6.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  209:            blk.6.ffn_up.5.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  210:          blk.6.ffn_gate.6.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  211:          blk.6.ffn_down.6.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  212:            blk.6.ffn_up.6.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  213:          blk.6.ffn_gate.7.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  214:          blk.6.ffn_down.7.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  215:            blk.6.ffn_up.7.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  216:           blk.6.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  217:            blk.6.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  218:          blk.7.ffn_gate.0.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  219:          blk.7.ffn_down.0.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  220:            blk.7.ffn_up.0.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  221:          blk.7.ffn_gate.1.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  222:          blk.7.ffn_down.1.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  223:            blk.7.ffn_up.1.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  224:          blk.7.ffn_gate.2.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  225:          blk.7.ffn_down.2.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  226:            blk.7.ffn_up.2.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  227:          blk.7.ffn_gate.3.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  228:          blk.7.ffn_down.3.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  229:            blk.7.ffn_up.3.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  230:          blk.7.ffn_gate.4.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  231:          blk.7.ffn_down.4.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  232:            blk.7.ffn_up.4.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  233:          blk.7.ffn_gate.5.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  234:          blk.7.ffn_down.5.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  235:            blk.7.ffn_up.5.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  236:          blk.7.ffn_gate.6.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  237:          blk.7.ffn_down.6.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  238:            blk.7.ffn_up.6.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  239:          blk.7.ffn_gate.7.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  240:          blk.7.ffn_down.7.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  241:            blk.7.ffn_up.7.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  242:        blk.7.ffn_gate_inp.weight f16      [  4096,     8,     1,     1 ]\n",
            "llama_model_loader: - tensor  243:           blk.7.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  244:            blk.7.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  245:              blk.7.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  246:         blk.7.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  247:              blk.7.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  248:              blk.7.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  249:          blk.8.ffn_gate.0.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  250:          blk.8.ffn_down.0.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  251:            blk.8.ffn_up.0.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  252:          blk.8.ffn_gate.1.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  253:          blk.8.ffn_down.1.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  254:            blk.8.ffn_up.1.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  255:          blk.8.ffn_gate.2.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  256:          blk.8.ffn_down.2.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  257:            blk.8.ffn_up.2.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  258:          blk.8.ffn_gate.3.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  259:        blk.8.ffn_gate_inp.weight f16      [  4096,     8,     1,     1 ]\n",
            "llama_model_loader: - tensor  260:              blk.8.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  261:         blk.8.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  262:              blk.8.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  263:              blk.8.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  264:         blk.10.ffn_gate.0.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  265:         blk.10.ffn_down.0.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  266:           blk.10.ffn_up.0.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  267:       blk.10.ffn_gate_inp.weight f16      [  4096,     8,     1,     1 ]\n",
            "llama_model_loader: - tensor  268:             blk.10.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  269:        blk.10.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  270:             blk.10.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  271:             blk.10.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  272:          blk.8.ffn_down.3.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  273:            blk.8.ffn_up.3.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  274:          blk.8.ffn_gate.4.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  275:          blk.8.ffn_down.4.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  276:            blk.8.ffn_up.4.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  277:          blk.8.ffn_gate.5.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  278:          blk.8.ffn_down.5.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  279:            blk.8.ffn_up.5.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  280:          blk.8.ffn_gate.6.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  281:          blk.8.ffn_down.6.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  282:            blk.8.ffn_up.6.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  283:          blk.8.ffn_gate.7.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  284:          blk.8.ffn_down.7.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  285:            blk.8.ffn_up.7.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  286:           blk.8.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  287:            blk.8.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  288:          blk.9.ffn_gate.0.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  289:          blk.9.ffn_down.0.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  290:            blk.9.ffn_up.0.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  291:          blk.9.ffn_gate.1.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  292:          blk.9.ffn_down.1.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  293:            blk.9.ffn_up.1.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  294:          blk.9.ffn_gate.2.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  295:          blk.9.ffn_down.2.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  296:            blk.9.ffn_up.2.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  297:          blk.9.ffn_gate.3.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  298:          blk.9.ffn_down.3.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  299:            blk.9.ffn_up.3.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  300:          blk.9.ffn_gate.4.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  301:          blk.9.ffn_down.4.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  302:            blk.9.ffn_up.4.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  303:          blk.9.ffn_gate.5.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  304:          blk.9.ffn_down.5.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  305:            blk.9.ffn_up.5.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  306:          blk.9.ffn_gate.6.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  307:          blk.9.ffn_down.6.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  308:            blk.9.ffn_up.6.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  309:          blk.9.ffn_gate.7.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  310:          blk.9.ffn_down.7.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  311:            blk.9.ffn_up.7.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  312:        blk.9.ffn_gate_inp.weight f16      [  4096,     8,     1,     1 ]\n",
            "llama_model_loader: - tensor  313:           blk.9.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  314:            blk.9.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  315:              blk.9.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  316:         blk.9.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  317:              blk.9.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  318:              blk.9.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  319:         blk.10.ffn_gate.1.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  320:         blk.10.ffn_down.1.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  321:           blk.10.ffn_up.1.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  322:         blk.10.ffn_gate.2.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  323:         blk.10.ffn_down.2.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  324:           blk.10.ffn_up.2.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  325:         blk.10.ffn_gate.3.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  326:         blk.10.ffn_down.3.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  327:           blk.10.ffn_up.3.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  328:         blk.10.ffn_gate.4.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  329:         blk.10.ffn_down.4.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  330:           blk.10.ffn_up.4.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  331:         blk.10.ffn_gate.5.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  332:         blk.10.ffn_down.5.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  333:           blk.10.ffn_up.5.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  334:         blk.10.ffn_gate.6.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  335:         blk.10.ffn_down.6.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  336:           blk.10.ffn_up.6.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  337:         blk.10.ffn_gate.7.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  338:         blk.10.ffn_down.7.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  339:           blk.10.ffn_up.7.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  340:          blk.10.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  341:           blk.10.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  342:         blk.11.ffn_gate.0.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  343:         blk.11.ffn_down.0.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  344:           blk.11.ffn_up.0.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  345:         blk.11.ffn_gate.1.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  346:         blk.11.ffn_down.1.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  347:           blk.11.ffn_up.1.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  348:         blk.11.ffn_gate.2.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  349:         blk.11.ffn_down.2.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  350:           blk.11.ffn_up.2.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  351:         blk.11.ffn_gate.3.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  352:         blk.11.ffn_down.3.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  353:           blk.11.ffn_up.3.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  354:         blk.11.ffn_gate.4.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  355:         blk.11.ffn_down.4.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  356:           blk.11.ffn_up.4.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  357:         blk.11.ffn_gate.5.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  358:         blk.11.ffn_down.5.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  359:           blk.11.ffn_up.5.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  360:         blk.11.ffn_gate.6.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  361:         blk.11.ffn_down.6.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  362:       blk.11.ffn_gate_inp.weight f16      [  4096,     8,     1,     1 ]\n",
            "llama_model_loader: - tensor  363:             blk.11.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  364:        blk.11.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  365:             blk.11.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  366:             blk.11.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  367:           blk.11.ffn_up.6.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  368:         blk.11.ffn_gate.7.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  369:         blk.11.ffn_down.7.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  370:           blk.11.ffn_up.7.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  371:          blk.11.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  372:           blk.11.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  373:         blk.12.ffn_gate.0.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  374:         blk.12.ffn_down.0.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  375:           blk.12.ffn_up.0.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  376:         blk.12.ffn_gate.1.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  377:         blk.12.ffn_down.1.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  378:           blk.12.ffn_up.1.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  379:         blk.12.ffn_gate.2.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  380:         blk.12.ffn_down.2.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  381:           blk.12.ffn_up.2.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  382:         blk.12.ffn_gate.3.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  383:         blk.12.ffn_down.3.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  384:           blk.12.ffn_up.3.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  385:         blk.12.ffn_gate.4.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  386:         blk.12.ffn_down.4.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  387:           blk.12.ffn_up.4.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  388:         blk.12.ffn_gate.5.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  389:         blk.12.ffn_down.5.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  390:           blk.12.ffn_up.5.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  391:         blk.12.ffn_gate.6.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  392:         blk.12.ffn_down.6.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  393:           blk.12.ffn_up.6.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  394:         blk.12.ffn_gate.7.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  395:         blk.12.ffn_down.7.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  396:           blk.12.ffn_up.7.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  397:       blk.12.ffn_gate_inp.weight f16      [  4096,     8,     1,     1 ]\n",
            "llama_model_loader: - tensor  398:          blk.12.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  399:           blk.12.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  400:             blk.12.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  401:        blk.12.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  402:             blk.12.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  403:             blk.12.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  404:         blk.13.ffn_gate.0.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  405:         blk.13.ffn_down.0.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  406:           blk.13.ffn_up.0.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  407:         blk.13.ffn_gate.1.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  408:         blk.13.ffn_down.1.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  409:           blk.13.ffn_up.1.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  410:         blk.13.ffn_gate.2.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  411:         blk.13.ffn_down.2.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  412:           blk.13.ffn_up.2.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  413:         blk.13.ffn_gate.3.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  414:         blk.13.ffn_down.3.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  415:           blk.13.ffn_up.3.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  416:         blk.13.ffn_gate.4.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  417:       blk.13.ffn_gate_inp.weight f16      [  4096,     8,     1,     1 ]\n",
            "llama_model_loader: - tensor  418:             blk.13.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  419:        blk.13.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  420:             blk.13.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  421:             blk.13.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  422:         blk.13.ffn_down.4.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  423:           blk.13.ffn_up.4.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  424:         blk.13.ffn_gate.5.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  425:         blk.13.ffn_down.5.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  426:           blk.13.ffn_up.5.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  427:         blk.13.ffn_gate.6.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  428:         blk.13.ffn_down.6.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  429:           blk.13.ffn_up.6.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  430:         blk.13.ffn_gate.7.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  431:         blk.13.ffn_down.7.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  432:           blk.13.ffn_up.7.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  433:          blk.13.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  434:           blk.13.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  435:         blk.14.ffn_gate.0.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  436:         blk.14.ffn_down.0.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  437:           blk.14.ffn_up.0.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  438:         blk.14.ffn_gate.1.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  439:         blk.14.ffn_down.1.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  440:           blk.14.ffn_up.1.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  441:         blk.14.ffn_gate.2.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  442:         blk.14.ffn_down.2.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  443:           blk.14.ffn_up.2.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  444:         blk.14.ffn_gate.3.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  445:         blk.14.ffn_down.3.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  446:           blk.14.ffn_up.3.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  447:         blk.14.ffn_gate.4.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  448:         blk.14.ffn_down.4.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  449:           blk.14.ffn_up.4.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  450:         blk.14.ffn_gate.5.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  451:         blk.14.ffn_down.5.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  452:           blk.14.ffn_up.5.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  453:         blk.14.ffn_gate.6.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  454:         blk.14.ffn_down.6.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  455:           blk.14.ffn_up.6.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  456:         blk.14.ffn_gate.7.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  457:         blk.14.ffn_down.7.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  458:           blk.14.ffn_up.7.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  459:       blk.14.ffn_gate_inp.weight f16      [  4096,     8,     1,     1 ]\n",
            "llama_model_loader: - tensor  460:          blk.14.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  461:           blk.14.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  462:             blk.14.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  463:        blk.14.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  464:             blk.14.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  465:             blk.14.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  466:         blk.15.ffn_gate.0.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  467:         blk.15.ffn_down.0.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  468:           blk.15.ffn_up.0.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  469:         blk.15.ffn_gate.1.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  470:         blk.15.ffn_down.1.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  471:           blk.15.ffn_up.1.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  472:       blk.15.ffn_gate_inp.weight f16      [  4096,     8,     1,     1 ]\n",
            "llama_model_loader: - tensor  473:             blk.15.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  474:        blk.15.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  475:             blk.15.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  476:             blk.15.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  477:         blk.15.ffn_gate.2.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  478:         blk.15.ffn_down.2.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  479:           blk.15.ffn_up.2.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  480:         blk.15.ffn_gate.3.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  481:         blk.15.ffn_down.3.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  482:           blk.15.ffn_up.3.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  483:         blk.15.ffn_gate.4.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  484:         blk.15.ffn_down.4.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  485:           blk.15.ffn_up.4.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  486:         blk.15.ffn_gate.5.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  487:         blk.15.ffn_down.5.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  488:           blk.15.ffn_up.5.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  489:         blk.15.ffn_gate.6.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  490:         blk.15.ffn_down.6.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  491:           blk.15.ffn_up.6.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  492:         blk.15.ffn_gate.7.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  493:         blk.15.ffn_down.7.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  494:           blk.15.ffn_up.7.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  495:          blk.15.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  496:           blk.15.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  497:         blk.16.ffn_gate.0.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  498:         blk.16.ffn_down.0.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  499:           blk.16.ffn_up.0.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  500:         blk.16.ffn_gate.1.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  501:         blk.16.ffn_down.1.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  502:           blk.16.ffn_up.1.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  503:         blk.16.ffn_gate.2.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  504:         blk.16.ffn_down.2.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  505:           blk.16.ffn_up.2.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  506:         blk.16.ffn_gate.3.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  507:         blk.16.ffn_down.3.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  508:           blk.16.ffn_up.3.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  509:         blk.16.ffn_gate.4.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  510:         blk.16.ffn_down.4.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  511:           blk.16.ffn_up.4.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  512:         blk.16.ffn_gate.5.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  513:         blk.16.ffn_down.5.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  514:           blk.16.ffn_up.5.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  515:         blk.16.ffn_gate.6.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  516:         blk.16.ffn_down.6.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  517:           blk.16.ffn_up.6.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  518:         blk.16.ffn_gate.7.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  519:         blk.16.ffn_down.7.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  520:       blk.16.ffn_gate_inp.weight f16      [  4096,     8,     1,     1 ]\n",
            "llama_model_loader: - tensor  521:             blk.16.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  522:        blk.16.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  523:             blk.16.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  524:             blk.16.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  525:           blk.16.ffn_up.7.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  526:          blk.16.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  527:           blk.16.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  528:         blk.17.ffn_gate.0.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  529:         blk.17.ffn_down.0.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  530:           blk.17.ffn_up.0.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  531:         blk.17.ffn_gate.1.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  532:         blk.17.ffn_down.1.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  533:           blk.17.ffn_up.1.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  534:         blk.17.ffn_gate.2.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  535:         blk.17.ffn_down.2.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  536:           blk.17.ffn_up.2.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  537:         blk.17.ffn_gate.3.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  538:         blk.17.ffn_down.3.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  539:           blk.17.ffn_up.3.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  540:         blk.17.ffn_gate.4.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  541:         blk.17.ffn_down.4.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  542:           blk.17.ffn_up.4.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  543:         blk.17.ffn_gate.5.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  544:         blk.17.ffn_down.5.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  545:           blk.17.ffn_up.5.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  546:         blk.17.ffn_gate.6.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  547:         blk.17.ffn_down.6.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  548:           blk.17.ffn_up.6.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  549:         blk.17.ffn_gate.7.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  550:         blk.17.ffn_down.7.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  551:           blk.17.ffn_up.7.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  552:       blk.17.ffn_gate_inp.weight f16      [  4096,     8,     1,     1 ]\n",
            "llama_model_loader: - tensor  553:          blk.17.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  554:           blk.17.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  555:             blk.17.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  556:        blk.17.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  557:             blk.17.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  558:             blk.17.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  559:         blk.18.ffn_gate.0.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  560:         blk.18.ffn_down.0.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  561:           blk.18.ffn_up.0.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  562:         blk.18.ffn_gate.1.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  563:         blk.18.ffn_down.1.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  564:           blk.18.ffn_up.1.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  565:         blk.18.ffn_gate.2.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  566:         blk.18.ffn_down.2.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  567:           blk.18.ffn_up.2.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  568:         blk.18.ffn_gate.3.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  569:         blk.18.ffn_down.3.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  570:           blk.18.ffn_up.3.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  571:         blk.18.ffn_gate.4.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  572:         blk.18.ffn_down.4.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  573:           blk.18.ffn_up.4.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  574:         blk.18.ffn_gate.5.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  575:       blk.18.ffn_gate_inp.weight f16      [  4096,     8,     1,     1 ]\n",
            "llama_model_loader: - tensor  576:             blk.18.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  577:        blk.18.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  578:             blk.18.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  579:             blk.18.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  580:         blk.18.ffn_down.5.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  581:           blk.18.ffn_up.5.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  582:         blk.18.ffn_gate.6.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  583:         blk.18.ffn_down.6.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  584:           blk.18.ffn_up.6.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  585:         blk.18.ffn_gate.7.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  586:         blk.18.ffn_down.7.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  587:           blk.18.ffn_up.7.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  588:          blk.18.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  589:           blk.18.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  590:         blk.19.ffn_gate.0.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  591:         blk.19.ffn_down.0.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  592:           blk.19.ffn_up.0.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  593:         blk.19.ffn_gate.1.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  594:         blk.19.ffn_down.1.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  595:           blk.19.ffn_up.1.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  596:         blk.19.ffn_gate.2.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  597:         blk.19.ffn_down.2.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  598:           blk.19.ffn_up.2.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  599:         blk.19.ffn_gate.3.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  600:         blk.19.ffn_down.3.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  601:           blk.19.ffn_up.3.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  602:         blk.19.ffn_gate.4.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  603:         blk.19.ffn_down.4.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  604:           blk.19.ffn_up.4.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  605:         blk.19.ffn_gate.5.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  606:         blk.19.ffn_down.5.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  607:           blk.19.ffn_up.5.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  608:         blk.19.ffn_gate.6.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  609:         blk.19.ffn_down.6.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  610:           blk.19.ffn_up.6.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  611:         blk.19.ffn_gate.7.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  612:         blk.19.ffn_down.7.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  613:           blk.19.ffn_up.7.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  614:       blk.19.ffn_gate_inp.weight f16      [  4096,     8,     1,     1 ]\n",
            "llama_model_loader: - tensor  615:          blk.19.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  616:           blk.19.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  617:             blk.19.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  618:        blk.19.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  619:             blk.19.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  620:             blk.19.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  621:         blk.20.ffn_gate.0.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  622:         blk.20.ffn_down.0.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  623:           blk.20.ffn_up.0.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  624:         blk.20.ffn_gate.1.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  625:         blk.20.ffn_down.1.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  626:           blk.20.ffn_up.1.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  627:         blk.20.ffn_gate.2.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  628:         blk.20.ffn_down.2.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  629:           blk.20.ffn_up.2.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  630:       blk.20.ffn_gate_inp.weight f16      [  4096,     8,     1,     1 ]\n",
            "llama_model_loader: - tensor  631:             blk.20.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  632:        blk.20.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  633:             blk.20.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  634:             blk.20.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  635:         blk.20.ffn_gate.3.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  636:         blk.20.ffn_down.3.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  637:           blk.20.ffn_up.3.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  638:         blk.20.ffn_gate.4.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  639:         blk.20.ffn_down.4.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  640:           blk.20.ffn_up.4.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  641:         blk.20.ffn_gate.5.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  642:         blk.20.ffn_down.5.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  643:           blk.20.ffn_up.5.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  644:         blk.20.ffn_gate.6.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  645:         blk.20.ffn_down.6.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  646:           blk.20.ffn_up.6.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  647:         blk.20.ffn_gate.7.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  648:         blk.20.ffn_down.7.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  649:           blk.20.ffn_up.7.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  650:          blk.20.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  651:           blk.20.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  652:         blk.21.ffn_gate.0.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  653:         blk.21.ffn_down.0.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  654:           blk.21.ffn_up.0.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  655:         blk.21.ffn_gate.1.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  656:         blk.21.ffn_down.1.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  657:           blk.21.ffn_up.1.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  658:         blk.21.ffn_gate.2.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  659:         blk.21.ffn_down.2.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  660:           blk.21.ffn_up.2.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  661:         blk.21.ffn_gate.3.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  662:         blk.21.ffn_down.3.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  663:           blk.21.ffn_up.3.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  664:         blk.21.ffn_gate.4.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  665:         blk.21.ffn_down.4.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  666:           blk.21.ffn_up.4.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  667:         blk.21.ffn_gate.5.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  668:         blk.21.ffn_down.5.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  669:           blk.21.ffn_up.5.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  670:         blk.21.ffn_gate.6.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  671:         blk.21.ffn_down.6.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  672:           blk.21.ffn_up.6.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  673:         blk.21.ffn_gate.7.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  674:         blk.21.ffn_down.7.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  675:           blk.21.ffn_up.7.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  676:       blk.21.ffn_gate_inp.weight f16      [  4096,     8,     1,     1 ]\n",
            "llama_model_loader: - tensor  677:          blk.21.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  678:           blk.21.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  679:             blk.21.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  680:        blk.21.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  681:             blk.21.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  682:             blk.21.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  683:         blk.22.ffn_gate.0.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  684:         blk.22.ffn_down.0.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  685:       blk.22.ffn_gate_inp.weight f16      [  4096,     8,     1,     1 ]\n",
            "llama_model_loader: - tensor  686:             blk.22.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  687:        blk.22.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  688:             blk.22.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  689:             blk.22.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  690:           blk.22.ffn_up.0.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  691:         blk.22.ffn_gate.1.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  692:         blk.22.ffn_down.1.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  693:           blk.22.ffn_up.1.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  694:         blk.22.ffn_gate.2.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  695:         blk.22.ffn_down.2.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  696:           blk.22.ffn_up.2.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  697:         blk.22.ffn_gate.3.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  698:         blk.22.ffn_down.3.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  699:           blk.22.ffn_up.3.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  700:         blk.22.ffn_gate.4.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  701:         blk.22.ffn_down.4.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  702:           blk.22.ffn_up.4.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  703:         blk.22.ffn_gate.5.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  704:         blk.22.ffn_down.5.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  705:           blk.22.ffn_up.5.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  706:         blk.22.ffn_gate.6.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  707:         blk.22.ffn_down.6.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  708:           blk.22.ffn_up.6.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  709:         blk.22.ffn_gate.7.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  710:         blk.22.ffn_down.7.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  711:           blk.22.ffn_up.7.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  712:          blk.22.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  713:           blk.22.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  714:         blk.23.ffn_gate.0.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  715:         blk.23.ffn_down.0.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  716:           blk.23.ffn_up.0.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  717:         blk.23.ffn_gate.1.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  718:         blk.23.ffn_down.1.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  719:           blk.23.ffn_up.1.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  720:         blk.23.ffn_gate.2.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  721:         blk.23.ffn_down.2.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  722:           blk.23.ffn_up.2.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  723:         blk.23.ffn_gate.3.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  724:         blk.23.ffn_down.3.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  725:           blk.23.ffn_up.3.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  726:         blk.23.ffn_gate.4.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  727:         blk.23.ffn_down.4.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  728:           blk.23.ffn_up.4.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  729:         blk.23.ffn_gate.5.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  730:         blk.23.ffn_down.5.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  731:           blk.23.ffn_up.5.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  732:         blk.23.ffn_gate.6.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  733:       blk.23.ffn_gate_inp.weight f16      [  4096,     8,     1,     1 ]\n",
            "llama_model_loader: - tensor  734:             blk.23.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  735:        blk.23.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  736:             blk.23.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  737:             blk.23.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  738:         blk.23.ffn_down.6.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  739:           blk.23.ffn_up.6.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  740:         blk.23.ffn_gate.7.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  741:         blk.23.ffn_down.7.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  742:           blk.23.ffn_up.7.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  743:          blk.23.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  744:           blk.23.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  745:         blk.24.ffn_gate.0.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  746:         blk.24.ffn_down.0.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  747:           blk.24.ffn_up.0.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  748:         blk.24.ffn_gate.1.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  749:         blk.24.ffn_down.1.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  750:           blk.24.ffn_up.1.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  751:         blk.24.ffn_gate.2.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  752:         blk.24.ffn_down.2.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  753:           blk.24.ffn_up.2.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  754:         blk.24.ffn_gate.3.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  755:         blk.24.ffn_down.3.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  756:           blk.24.ffn_up.3.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  757:         blk.24.ffn_gate.4.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  758:         blk.24.ffn_down.4.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  759:           blk.24.ffn_up.4.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  760:         blk.24.ffn_gate.5.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  761:         blk.24.ffn_down.5.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  762:           blk.24.ffn_up.5.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  763:         blk.24.ffn_gate.6.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  764:         blk.24.ffn_down.6.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  765:           blk.24.ffn_up.6.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  766:         blk.24.ffn_gate.7.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  767:         blk.24.ffn_down.7.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  768:           blk.24.ffn_up.7.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  769:       blk.24.ffn_gate_inp.weight f16      [  4096,     8,     1,     1 ]\n",
            "llama_model_loader: - tensor  770:          blk.24.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  771:           blk.24.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  772:             blk.24.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  773:        blk.24.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  774:             blk.24.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  775:             blk.24.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  776:         blk.25.ffn_gate.0.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  777:         blk.25.ffn_down.0.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  778:           blk.25.ffn_up.0.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  779:         blk.25.ffn_gate.1.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  780:         blk.25.ffn_down.1.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  781:           blk.25.ffn_up.1.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  782:         blk.25.ffn_gate.2.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  783:         blk.25.ffn_down.2.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  784:           blk.25.ffn_up.2.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  785:         blk.25.ffn_gate.3.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  786:         blk.25.ffn_down.3.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  787:           blk.25.ffn_up.3.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  788:       blk.25.ffn_gate_inp.weight f16      [  4096,     8,     1,     1 ]\n",
            "llama_model_loader: - tensor  789:             blk.25.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  790:        blk.25.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  791:             blk.25.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  792:             blk.25.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  793:         blk.25.ffn_gate.4.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  794:         blk.25.ffn_down.4.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  795:           blk.25.ffn_up.4.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  796:         blk.25.ffn_gate.5.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  797:         blk.25.ffn_down.5.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  798:           blk.25.ffn_up.5.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  799:         blk.25.ffn_gate.6.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  800:         blk.25.ffn_down.6.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  801:           blk.25.ffn_up.6.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  802:         blk.25.ffn_gate.7.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  803:         blk.25.ffn_down.7.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  804:           blk.25.ffn_up.7.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  805:          blk.25.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  806:           blk.25.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  807:         blk.26.ffn_gate.0.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  808:         blk.26.ffn_down.0.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  809:           blk.26.ffn_up.0.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  810:         blk.26.ffn_gate.1.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  811:         blk.26.ffn_down.1.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  812:           blk.26.ffn_up.1.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  813:         blk.26.ffn_gate.2.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  814:         blk.26.ffn_down.2.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  815:           blk.26.ffn_up.2.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  816:         blk.26.ffn_gate.3.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  817:         blk.26.ffn_down.3.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  818:           blk.26.ffn_up.3.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  819:         blk.26.ffn_gate.4.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  820:         blk.26.ffn_down.4.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  821:           blk.26.ffn_up.4.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  822:         blk.26.ffn_gate.5.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  823:         blk.26.ffn_down.5.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  824:           blk.26.ffn_up.5.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  825:         blk.26.ffn_gate.6.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  826:         blk.26.ffn_down.6.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  827:           blk.26.ffn_up.6.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  828:         blk.26.ffn_gate.7.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  829:         blk.26.ffn_down.7.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  830:           blk.26.ffn_up.7.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  831:       blk.26.ffn_gate_inp.weight f16      [  4096,     8,     1,     1 ]\n",
            "llama_model_loader: - tensor  832:          blk.26.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  833:           blk.26.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  834:             blk.26.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  835:        blk.26.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  836:             blk.26.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  837:             blk.26.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  838:         blk.27.ffn_gate.0.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  839:         blk.27.ffn_down.0.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  840:           blk.27.ffn_up.0.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  841:         blk.27.ffn_gate.1.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  842:         blk.27.ffn_down.1.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  843:       blk.27.ffn_gate_inp.weight f16      [  4096,     8,     1,     1 ]\n",
            "llama_model_loader: - tensor  844:             blk.27.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  845:        blk.27.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  846:             blk.27.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  847:             blk.27.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  848:           blk.27.ffn_up.1.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  849:         blk.27.ffn_gate.2.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  850:         blk.27.ffn_down.2.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  851:           blk.27.ffn_up.2.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  852:         blk.27.ffn_gate.3.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  853:         blk.27.ffn_down.3.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  854:           blk.27.ffn_up.3.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  855:         blk.27.ffn_gate.4.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  856:         blk.27.ffn_down.4.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  857:           blk.27.ffn_up.4.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  858:         blk.27.ffn_gate.5.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  859:         blk.27.ffn_down.5.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  860:           blk.27.ffn_up.5.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  861:         blk.27.ffn_gate.6.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  862:         blk.27.ffn_down.6.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  863:           blk.27.ffn_up.6.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  864:         blk.27.ffn_gate.7.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  865:         blk.27.ffn_down.7.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  866:           blk.27.ffn_up.7.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  867:          blk.27.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  868:           blk.27.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  869:         blk.28.ffn_gate.0.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  870:         blk.28.ffn_down.0.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  871:           blk.28.ffn_up.0.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  872:         blk.28.ffn_gate.1.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  873:         blk.28.ffn_down.1.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  874:           blk.28.ffn_up.1.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  875:         blk.28.ffn_gate.2.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  876:         blk.28.ffn_down.2.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  877:           blk.28.ffn_up.2.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  878:         blk.28.ffn_gate.3.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  879:         blk.28.ffn_down.3.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  880:           blk.28.ffn_up.3.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  881:         blk.28.ffn_gate.4.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  882:         blk.28.ffn_down.4.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  883:           blk.28.ffn_up.4.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  884:         blk.28.ffn_gate.5.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  885:         blk.28.ffn_down.5.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  886:           blk.28.ffn_up.5.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  887:         blk.28.ffn_gate.6.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  888:         blk.28.ffn_down.6.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  889:           blk.28.ffn_up.6.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  890:         blk.28.ffn_gate.7.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  891:       blk.28.ffn_gate_inp.weight f16      [  4096,     8,     1,     1 ]\n",
            "llama_model_loader: - tensor  892:             blk.28.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  893:        blk.28.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  894:             blk.28.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  895:             blk.28.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  896:         blk.28.ffn_down.7.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  897:           blk.28.ffn_up.7.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  898:          blk.28.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  899:           blk.28.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  900:         blk.29.ffn_gate.0.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  901:         blk.29.ffn_down.0.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  902:           blk.29.ffn_up.0.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  903:         blk.29.ffn_gate.1.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  904:         blk.29.ffn_down.1.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  905:           blk.29.ffn_up.1.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  906:         blk.29.ffn_gate.2.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  907:         blk.29.ffn_down.2.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  908:           blk.29.ffn_up.2.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  909:         blk.29.ffn_gate.3.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  910:         blk.29.ffn_down.3.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  911:           blk.29.ffn_up.3.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  912:         blk.29.ffn_gate.4.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  913:         blk.29.ffn_down.4.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  914:           blk.29.ffn_up.4.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  915:         blk.29.ffn_gate.5.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  916:         blk.29.ffn_down.5.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  917:           blk.29.ffn_up.5.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  918:         blk.29.ffn_gate.6.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  919:         blk.29.ffn_down.6.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  920:           blk.29.ffn_up.6.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  921:         blk.29.ffn_gate.7.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  922:         blk.29.ffn_down.7.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  923:           blk.29.ffn_up.7.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  924:       blk.29.ffn_gate_inp.weight f16      [  4096,     8,     1,     1 ]\n",
            "llama_model_loader: - tensor  925:          blk.29.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  926:           blk.29.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  927:             blk.29.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  928:        blk.29.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  929:             blk.29.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  930:             blk.29.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  931:         blk.30.ffn_gate.0.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  932:         blk.30.ffn_down.0.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  933:           blk.30.ffn_up.0.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  934:         blk.30.ffn_gate.1.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  935:         blk.30.ffn_down.1.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  936:           blk.30.ffn_up.1.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  937:         blk.30.ffn_gate.2.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  938:         blk.30.ffn_down.2.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  939:           blk.30.ffn_up.2.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  940:         blk.30.ffn_gate.3.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  941:         blk.30.ffn_down.3.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  942:           blk.30.ffn_up.3.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  943:         blk.30.ffn_gate.4.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  944:         blk.30.ffn_down.4.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  945:           blk.30.ffn_up.4.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  946:       blk.30.ffn_gate_inp.weight f16      [  4096,     8,     1,     1 ]\n",
            "llama_model_loader: - tensor  947:             blk.30.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  948:        blk.30.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  949:             blk.30.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  950:             blk.30.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  951:                    output.weight q6_K     [  4096, 32000,     1,     1 ]\n",
            "llama_model_loader: - tensor  952:         blk.30.ffn_gate.5.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  953:         blk.30.ffn_down.5.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  954:           blk.30.ffn_up.5.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  955:         blk.30.ffn_gate.6.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  956:         blk.30.ffn_down.6.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  957:           blk.30.ffn_up.6.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  958:         blk.30.ffn_gate.7.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  959:         blk.30.ffn_down.7.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  960:           blk.30.ffn_up.7.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  961:          blk.30.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  962:           blk.30.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  963:         blk.31.ffn_gate.0.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  964:         blk.31.ffn_down.0.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  965:           blk.31.ffn_up.0.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  966:         blk.31.ffn_gate.1.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  967:         blk.31.ffn_down.1.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  968:           blk.31.ffn_up.1.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  969:         blk.31.ffn_gate.2.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  970:         blk.31.ffn_down.2.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  971:           blk.31.ffn_up.2.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  972:         blk.31.ffn_gate.3.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  973:         blk.31.ffn_down.3.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  974:           blk.31.ffn_up.3.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  975:         blk.31.ffn_gate.4.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  976:         blk.31.ffn_down.4.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  977:           blk.31.ffn_up.4.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  978:         blk.31.ffn_gate.5.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  979:         blk.31.ffn_down.5.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  980:           blk.31.ffn_up.5.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  981:         blk.31.ffn_gate.6.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  982:         blk.31.ffn_down.6.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  983:           blk.31.ffn_up.6.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  984:         blk.31.ffn_gate.7.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  985:         blk.31.ffn_down.7.weight q5_0     [ 14336,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  986:           blk.31.ffn_up.7.weight q5_0     [  4096, 14336,     1,     1 ]\n",
            "llama_model_loader: - tensor  987:       blk.31.ffn_gate_inp.weight f16      [  4096,     8,     1,     1 ]\n",
            "llama_model_loader: - tensor  988:          blk.31.attn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  989:           blk.31.ffn_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: - tensor  990:             blk.31.attn_k.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  991:        blk.31.attn_output.weight q5_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  992:             blk.31.attn_q.weight q5_0     [  4096,  4096,     1,     1 ]\n",
            "llama_model_loader: - tensor  993:             blk.31.attn_v.weight q8_0     [  4096,  1024,     1,     1 ]\n",
            "llama_model_loader: - tensor  994:               output_norm.weight f32      [  4096,     1,     1,     1 ]\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.name str              = mistralai_mixtral-8x7b-instruct-v0.1\n",
            "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
            "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
            "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
            "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
            "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
            "llama_model_loader: - kv   9:                         llama.expert_count u32              = 8\n",
            "llama_model_loader: - kv  10:                    llama.expert_used_count u32              = 2\n",
            "llama_model_loader: - kv  11:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  12:                       llama.rope.freq_base f32              = 1000000.000000\n",
            "llama_model_loader: - kv  13:                          general.file_type u32              = 8\n",
            "llama_model_loader: - kv  14:                       tokenizer.ggml.model str              = llama\n",
            "llama_model_loader: - kv  15:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
            "llama_model_loader: - kv  16:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
            "llama_model_loader: - kv  17:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
            "llama_model_loader: - kv  18:                tokenizer.ggml.bos_token_id u32              = 1\n",
            "llama_model_loader: - kv  19:                tokenizer.ggml.eos_token_id u32              = 2\n",
            "llama_model_loader: - kv  20:            tokenizer.ggml.unknown_token_id u32              = 0\n",
            "llama_model_loader: - kv  21:            tokenizer.ggml.padding_token_id u32              = 0\n",
            "llama_model_loader: - kv  22:               tokenizer.ggml.add_bos_token bool             = true\n",
            "llama_model_loader: - kv  23:               tokenizer.ggml.add_eos_token bool             = false\n",
            "llama_model_loader: - kv  24:                    tokenizer.chat_template str              = {{ bos_token }}{% for message in mess...\n",
            "llama_model_loader: - kv  25:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   65 tensors\n",
            "llama_model_loader: - type  f16:   32 tensors\n",
            "llama_model_loader: - type q5_0:  833 tensors\n",
            "llama_model_loader: - type q8_0:   64 tensors\n",
            "llama_model_loader: - type q6_K:    1 tensors\n",
            "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
            "llm_load_print_meta: format           = GGUF V3 (latest)\n",
            "llm_load_print_meta: arch             = llama\n",
            "llm_load_print_meta: vocab type       = SPM\n",
            "llm_load_print_meta: n_vocab          = 32000\n",
            "llm_load_print_meta: n_merges         = 0\n",
            "llm_load_print_meta: n_ctx_train      = 32768\n",
            "llm_load_print_meta: n_embd           = 4096\n",
            "llm_load_print_meta: n_head           = 32\n",
            "llm_load_print_meta: n_head_kv        = 8\n",
            "llm_load_print_meta: n_layer          = 32\n",
            "llm_load_print_meta: n_rot            = 128\n",
            "llm_load_print_meta: n_gqa            = 4\n",
            "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
            "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
            "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
            "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
            "llm_load_print_meta: n_ff             = 14336\n",
            "llm_load_print_meta: n_expert         = 8\n",
            "llm_load_print_meta: n_expert_used    = 2\n",
            "llm_load_print_meta: rope scaling     = linear\n",
            "llm_load_print_meta: freq_base_train  = 1000000.0\n",
            "llm_load_print_meta: freq_scale_train = 1\n",
            "llm_load_print_meta: n_yarn_orig_ctx  = 32768\n",
            "llm_load_print_meta: rope_finetuned   = unknown\n",
            "llm_load_print_meta: model type       = 7B\n",
            "llm_load_print_meta: model ftype      = Q5_0\n",
            "llm_load_print_meta: model params     = 46.70 B\n",
            "llm_load_print_meta: model size       = 30.02 GiB (5.52 BPW) \n",
            "llm_load_print_meta: general.name     = mistralai_mixtral-8x7b-instruct-v0.1\n",
            "llm_load_print_meta: BOS token        = 1 '<s>'\n",
            "llm_load_print_meta: EOS token        = 2 '</s>'\n",
            "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
            "llm_load_print_meta: PAD token        = 0 '<unk>'\n",
            "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
            "llm_load_tensors: ggml ctx size =    0.38 MiB\n",
            "llm_load_tensors: mem required  = 30735.87 MiB\n",
            "....................................................................................................\n",
            "llama_new_context_with_model: n_ctx      = 2048\n",
            "llama_new_context_with_model: freq_base  = 10000.0\n",
            "llama_new_context_with_model: freq_scale = 1\n",
            "llama_new_context_with_model: KV self size  =  256.00 MiB, K (f16):  128.00 MiB, V (f16):  128.00 MiB\n",
            "llama_build_graph: non-view tensors processed: 1124/1124\n",
            "llama_new_context_with_model: compute buffer total size = 6.06 MiB\n"
          ]
        }
      ],
      "source": [
        "##########################################################################################\n",
        "# Load the LLM and it's tokenizer\n",
        "# In this blog post, we're using the quantized version of Mixtral-8x7B-Instruct-v0.1\n",
        "##########################################################################################\n",
        "\n",
        "import os\n",
        "from transformers import AutoTokenizer\n",
        "from langchain.llms import LlamaCpp\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "llm = LlamaCpp(\n",
        "    model_path=MODEL_PATH,\n",
        "    temperature=0.2, #Controls the randomness of the model's output. A higher temperature (e.g., 1.0) produces more diverse but less focused output, while a lower temperature (e.g., 0.5) generates more focused and deterministic output.\n",
        "    max_tokens=4096, # Sets the maximum number of tokens (words or subwords) that the model can generate in a single inference. This helps limit the length of the output.\n",
        "    n_ctx=2048, # Sets the context window size for the model. It defines the length of the input sequence that the model considers when generating each token.\n",
        "    repetition_penalty=1.1, # Introduces a penalty for generating repeated tokens, encouraging the model to produce more diverse and non-repetitive output.\n",
        "    top_p=0.9, # Top-p allows for dynamic control of the number of tokens considered, leading to different levels of diversity in the generated text.\n",
        "    top_k=50, # Top-k provides a controlled randomness by considering a fixed number of top probable tokens\n",
        "    threads=int(os.cpu_count() / 2), # Specifies the number of threads to use during model execution, potentially parallelizing certain operations.\n",
        "    verbose=False,\n",
        "    stream=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "qR_f1O3hXmpr"
      },
      "outputs": [],
      "source": [
        "##########################################################################################\n",
        "# We now need to provide some recommended instructions for the agent to follow.\n",
        "# These instructions will be used by the agent when it is asked for some help.\n",
        "# The agent with the help of these instructions knows the DOs and DON'Ts of the task.\n",
        "# It also now knows on how to use the tools provided to it and how to respond to the user.\n",
        "##########################################################################################\n",
        "\n",
        "\n",
        "start_instruct = \"<s>[INST] \"\n",
        "end_instruct = \"[/INST]\"\n",
        "end_sentence = \"</s>\"\n",
        "system_message_plain = \"\"\"You are a helpful AI assistant for the purpose of captioning provided image. \n",
        "\n",
        "You are an agent capable of using only two tools, i.e., 'image_captioner' and 'Final Answer' available to caption an image and then answer follow-up question. \n",
        "\n",
        "Here are a few of the tools available to you along with the instructions on how to use them:\n",
        "\n",
        "- image_captioner: the image_captioner tool must be used when asked to caption or describe or explain an image. \n",
        "- Final Answer: the final answer tool must be used to respond to the user. You must use this when you have decided on an answer.\n",
        "\n",
        "To use these tools you must always respond in JSON format containing `\"action\"` and `\"action_input\"` key-value pairs. For example, if user asks you to caption or describe or explain an image, you must use the image_captioner tool like so:\n",
        "\n",
        "All of AI Assistant's communication is performed using this JSON format. Make sure to always respond in the JSON format without any exceptions.\n",
        "\n",
        "Description of the tools available to you:\n",
        "- \"image_captioner\": Useful when you need to get information about the image\n",
        "  - To use the image_captioner tool, Assistant should write like so:\n",
        "      ```json\n",
        "      {{\"action\": \"image_captioner\",\n",
        "        \"action_input\": \"https://xyz.png\"}}\n",
        "      ```\n",
        "\n",
        "- \"Final Answer\": Useful when you have used the tool, or the tool is not required and now you've finalised your answer and need to respond to the user\n",
        "  - To use the Final Answer tool, Assistant should write like so:\n",
        "      ```json\n",
        "      {{\"action\": \"Final Answer\",\n",
        "        \"action_input\": \"The answer to the user's question\"}}\n",
        "      ```\n",
        "  - The data type of `\"action\"` and `\"action_input\"` key-value pairs in the JSON format is always a string. It should never be another dictionary or list.\n",
        "    - Example of a valid response for `\"action_input\"`:\n",
        "      action_input\": \"value1\" # This is valid because the value of \"action_input\" is a string, value of \"action_input\" can never be a dictionary or list\n",
        "\n",
        "Here are some previous conversations between the Assistant and User:\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "system_message = start_instruct + system_message_plain + end_instruct + end_sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "O-_T8FkvXmnq"
      },
      "outputs": [],
      "source": [
        "#################################################################################################################\n",
        "# We now need to define the agent's behaviour. \n",
        "# This is done by providing agent with some examples in form of context\n",
        "# By providing the agent with some examples, we are telling the agent how to respond to the user.\n",
        "# This is really important as it helps the agent to learn how to respond to the user which makes our life easier.\n",
        "#################################################################################################################\n",
        "\n",
        "messages = [\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Hello how are you doing today?\"\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": '''```json\n",
        "{{\"action\": \"Final Answer\",\n",
        " \"action_input\": \"I'm doing well, thank you for asking! How are you doing today??\"}}\n",
        "```'''\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Provide me with the caption of this image - https://storage.googleapis.com/sfr-vision-language-research/BLIP/demo.jpg ?\"\n",
        "        },\n",
        "            {\"role\": \"assistant\",\n",
        "            \"content\": '''```json\n",
        "{{\"action\": \"image_captioner\",\n",
        " \"action_input\": \"https://storage.googleapis.com/sfr-vision-language-research/BLIP/demo.jpg\"}}\n",
        "```'''\n",
        "        },{\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"a woman sitting on the beach with her dog\"\n",
        "        },\n",
        "            {\"role\": \"assistant\",\n",
        "            \"content\": '''```json\n",
        "{{\"action\": \"Final Answer\",\n",
        " \"action_input\": \"This image shows a woman sitting on the beach with her dog\"}}\n",
        "```'''\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Thanks could you now provide me with the caption of this image - : https://www.adorama.com/alc/wp-content/uploads/2015/05/stories-HRX5WXFyB64-unsplash.jpg\"\n",
        "        },\n",
        "            {\"role\": \"assistant\",\n",
        "            \"content\": '''```json\n",
        "{{\"action\": \"image_captioner\",\n",
        " \"action_input\": \"https://www.adorama.com/alc/wp-content/uploads/2015/05/stories-HRX5WXFyB64-unsplash.jpg\"}}\n",
        "```'''\n",
        "        },{\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"a beach with sun setting in the background\"\n",
        "        },\n",
        "            {\"role\": \"assistant\",\n",
        "            \"content\": '''```json\n",
        "{{\"action\": \"Final Answer\",\n",
        " \"action_input\": \"The image is of a sunset on the beach\"}}\n",
        "```'''\n",
        "        }\n",
        "]\n",
        "\n",
        "conversation_formatted = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "#################################################################################################################\n",
        "# Finally, we combine all instructions and examples (in correct format) prompt to create the final prompt.\n",
        "#################################################################################################################\n",
        "\n",
        "prompt = system_message + '\\n\\n' + conversation_formatted\n",
        "instruction = start_instruct + \" Respond to the following in JSON with 'action' and 'action_input' values \" + end_instruct\n",
        "human_msg = instruction + \"\\nUser: {input}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "############################################################################\n",
        "# We now need to define the output parser for the agent. \n",
        "# This basically tells the agent how to parse the output from the agent.\n",
        "# Based on the parsed output, the agent will then respond to the user.\n",
        "############################################################################\n",
        "\n",
        "\n",
        "import re\n",
        "from langchain.agents import AgentOutputParser\n",
        "from langchain.schema import AgentAction, AgentFinish\n",
        "from langchain.output_parsers.json import parse_json_markdown\n",
        "from langchain.agents.conversational_chat.prompt import FORMAT_INSTRUCTIONS\n",
        "\n",
        "class OutputParser(AgentOutputParser):\n",
        "    def get_format_instructions(self) -> str:\n",
        "        return FORMAT_INSTRUCTIONS\n",
        "\n",
        "    def parse(self, text: str) -> AgentAction | AgentFinish:\n",
        "        try:\n",
        "            # we now need to parse the text as JSON\n",
        "            # this will give us the action and action_input that the agent wants to use\n",
        "            # this won't work if text is not a valid JSON string\n",
        "            response = parse_json_markdown(text)\n",
        "            action, action_input = response[\"action\"], response[\"action_input\"]\n",
        "            if action == \"Final Answer\":\n",
        "                # Once the agent gives the final answer, we call AgentFinish\n",
        "                return AgentFinish({\"output\": action_input}, text)\n",
        "            else:\n",
        "                # if not, we call AgentAction with the action and action_input\n",
        "                return AgentAction(action, action_input, text)\n",
        "        except Exception as e:\n",
        "            # At times, agent might not respond in the correct JSON format as we require to parse the JSON\n",
        "            # In such cases, we need to handle the exception and try to parse the text in a different way\n",
        "            # The whole point of this is to make sure that we parse the text even if it is not in the correct JSON format\n",
        "            # We do this by using regular expressions to find the content between the curly braces\n",
        "            # We then replace the backslashes in the content (If ANY) and then format the JSON string\n",
        "            # We then parse the formatted JSON string\n",
        "            # Even after this, sometimes the agent might not respond in the correct JSON format\n",
        "            # We'll then need to figure out a way to handle this as well\n",
        "            # But for now, we'll just return AgentFinish with the text as the output\n",
        "\n",
        "            try:\n",
        "                # Use regular expression to find content between {}\n",
        "                match = re.search(r'\\{([^}]*)\\}', text)\n",
        "                content_between_braces = match.group(1)\n",
        "\n",
        "                # Replace backslashes in the content\n",
        "                # At times, the agent returns action\\_input instead of action_input\n",
        "                escaped_content = content_between_braces.replace(\"\\\\\", \"\")\n",
        "                # Format the JSON string\n",
        "                formatted_json = f'''```json{{{escaped_content}}}```'''\n",
        "                # Parse the formatted JSON string and get the action and action_input\n",
        "                response = parse_json_markdown(formatted_json)\n",
        "                action, action_input = response[\"action\"], response[\"action_input\"]\n",
        "\n",
        "                # We then repeat the same process as above\n",
        "                if action == \"Final Answer\":\n",
        "                    # this means the agent is finished so we call AgentFinish\n",
        "                    return AgentFinish({\"output\": action_input}, text)\n",
        "                else:\n",
        "                    # otherwise the agent wants to use an action, so we call AgentAction\n",
        "                    return AgentAction(action, action_input, text)\n",
        "            except:\n",
        "                # If the agent still doesn't respond in the correct JSON format, we just call AgentFinish with the text as the output\n",
        "                return AgentFinish({\"output\": text}, text)\n",
        "\n",
        "    @property\n",
        "    def _type(self) -> str:\n",
        "        return \"conversational_chat\"\n",
        "    \n",
        "# Initialize parser\n",
        "parser = OutputParser()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "###################################################################################################################################################\n",
        "# We now need to initialize the agent with the tools we defined above, the LLM that we loaded above, the output parser that we defined above\n",
        "# We also need to provide the agent with the memory that it will use to store the previous interactions. This is really important if we want to\n",
        "# do Q&A with the agent. The agent will use the memory to store the previous interactions and then use them to answer the user's questions.\n",
        "###################################################################################################################################################\n",
        "\n",
        "\n",
        "from langchain.memory import ConversationBufferWindowMemory\n",
        "from langchain.agents.initialize import initialize_agent\n",
        "\n",
        "# Tracks and utilizes the latest K interactions in the conversation.\n",
        "memory = ConversationBufferWindowMemory(\n",
        "    memory_key=\"chat_history\", k=5, return_messages=True, output_key=\"output\"\n",
        ")\n",
        "\n",
        "agent = initialize_agent(\n",
        "    agent=\"chat-conversational-react-description\",\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    verbose=True,\n",
        "    early_stopping_method=\"generate\",\n",
        "    memory=memory,\n",
        "    handle_parsing_errors=False,\n",
        "    agent_kwargs={\"output_parser\": parser}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "##############################################################################\n",
        "# We now need to provide the agent with the prompt that we created above.\n",
        "# This prompt will be used by the agent to respond to the user.\n",
        "##############################################################################\n",
        "\n",
        "new_prompt = agent.agent.create_prompt(\n",
        "    system_message=prompt,\n",
        "    tools=tools\n",
        ")\n",
        "agent.agent.llm_chain.prompt = new_prompt\n",
        "agent.agent.llm_chain.prompt.messages[2].prompt.template = human_msg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "\n",
            "Assistant: {\n",
            "  \"action\": \"image_captioner\",\n",
            "  \"action_input\": \"https://images.hindustantimes.com/auto/img/2023/07/23/1600x900/Tesla_Cybertruck_1688887534001_1690087911053.jpeg\"\n",
            "}\n",
            "\n",
            "Assistant: {\n",
            "  \"action\": \"Final Answer\",\n",
            "  \"action_input\": \"The image shows the Tesla Cybertruck, an all-electric battery-powered light commercial vehicle.\"\n",
            "}\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3ma close up of a silver car parked on a parking lot\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "a close up of a silver car parked on a parking lot\n"
          ]
        }
      ],
      "source": [
        "resp = agent(\"Explain this image: https://images.hindustantimes.com/auto/img/2023/07/23/1600x900/Tesla_Cybertruck_1688887534001_1690087911053.jpeg\")\n",
        "print(resp['output'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "M3OD7tFbXmal",
        "outputId": "38962301-5953-4736-8f3f-4ed9a084e4bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "\n",
            "```json\n",
            "{\n",
            "  \"action\": \"Final Answer\",\n",
            "  \"action_input\": \"The color of the car appears to be silver.\"\n",
            "}\n",
            "```\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "The color of the car appears to be silver.\n"
          ]
        }
      ],
      "source": [
        "resp = agent('What is the color of the car?')\n",
        "print(resp['output'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "dodk2qyVXmVs"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "\n",
            "```json\n",
            "{\n",
            "  \"action\": \"Final Answer\",\n",
            "  \"action_input\": \"The brand of the car appears to be Tesla.\"\n",
            "}\n",
            "```\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "The brand of the car appears to be Tesla.\n"
          ]
        }
      ],
      "source": [
        "resp = agent('What is the brand of the car?')\n",
        "print(resp['output'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "\n",
            "Assistant: {\n",
            "  \"action\": \"Final Answer\",\n",
            "  \"action_input\": \"It is not possible to determine the number of people in the car based on the provided image.\"\n",
            "}\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "It is not possible to determine the number of people in the car based on the provided image.\n"
          ]
        }
      ],
      "source": [
        "resp = agent('How many people are there in the car?')\n",
        "print(resp['output'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[32;1m\u001b[1;3m\n",
            "\n",
            "```json\n",
            "{\n",
            "    \"action\": \"Final Answer\",\n",
            "    \"action_input\": \"Based on the provided image, it is not possible to identify specific features of the car. However, some common features of Tesla cars include Autopilot capabilities, a large touchscreen display, and a fully electric powertrain.\"\n",
            "}\n",
            "```\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Based on the provided image, it is not possible to identify specific features of the car. However, some common features of Tesla cars include Autopilot capabilities, a large touchscreen display, and a fully electric powertrain.\n"
          ]
        }
      ],
      "source": [
        "resp = agent('Explain the feature of this car?')\n",
        "print(resp['output'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0378eca5d7844b31880566dc2300e132": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_da835640583d4d19abae42a9f3c79256",
              "IPY_MODEL_99b8f6b62f2b4f7c81e90360a72d82ea",
              "IPY_MODEL_2c02a844c667469c937ba121fb71e84d"
            ],
            "layout": "IPY_MODEL_192f79c36b514290aaa0c16d372e6556"
          }
        },
        "04d94de09a7447048ef4c48b3397cae5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05dc9528231e42a2b04f51d2ea883f4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b8a4297663048b48459460bdb567a61",
            "max": 287,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ad583990677b4d1fb4d55843d6ae3b1a",
            "value": 287
          }
        },
        "0cddf0ee2fde4955948545b6548d021f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f7ae4cd186242c783429cb974531231": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1150c71179e44863af4efa90cddc56d3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16e9fd2e805c49da9a5038be60fb9d9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8b7f960d70245599f27670784a655b9",
            "placeholder": "",
            "style": "IPY_MODEL_771a083f78db46318a74582943f06499",
            "value": "preprocessor_config.json: 100%"
          }
        },
        "1735a9f9df4149a098f02cf7257be709": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6812e411ea92445483b26d363554757f",
            "placeholder": "",
            "style": "IPY_MODEL_472c68127b0d4c8f93396aaac1b7f9f8",
            "value": " 125/125 [00:00&lt;00:00, 3.70kB/s]"
          }
        },
        "192f79c36b514290aaa0c16d372e6556": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19475b0c66414555b587a9a825a8268c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a8e6dede4064f6faa325066967d4429",
            "placeholder": "",
            "style": "IPY_MODEL_98ce626cff4941bba945d890fce08369",
            "value": " 506/506 [00:00&lt;00:00, 22.8kB/s]"
          }
        },
        "1bb03ad1e1644edca469f318f18ce46b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1bb1a8a8c3f24231877b4bccbc13f9ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1f8873c92d77410992514027c3e32c01": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_70d3a73dce5c4f7abc3b59efa51ab4c2",
              "IPY_MODEL_441b2fdb21a44ecc85e5d6533bcef753",
              "IPY_MODEL_e7f2b76fe23c4e749221de97d54ffbc8"
            ],
            "layout": "IPY_MODEL_9c0069b1dbf34d2cbc1f5622809df235"
          }
        },
        "20b4baa1531040f5bc5c0ff2b43a241c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_860dc1e9cd5e4f7eba338a793d761825",
            "max": 125,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e57a8ac878b7489e8bb9576a13170c3c",
            "value": 125
          }
        },
        "216c095e28a44ee484c90f79e6b89b88": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "21d288bd26b742188c4bf140dfd2e458": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e8bcbde84bc4867a2ccfeb59928747b",
            "max": 506,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_216c095e28a44ee484c90f79e6b89b88",
            "value": 506
          }
        },
        "228fb7fc4fa74818b911ec77e1ce335e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8d9d9912947644dd9aa77b08ce25478c",
              "IPY_MODEL_34c3b1a8055c47ea936113d26de06ab6",
              "IPY_MODEL_64b0fcb359994072acbff3ac0c5b7f14"
            ],
            "layout": "IPY_MODEL_b34dd15c42184d46bfac9aa28ee5b875"
          }
        },
        "2317f58d4faf4c4898083baf13b9f43c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2986bf8401b94d46b52936e6f128219e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_467317077d5e4c0c9ad9583f120b434b",
              "IPY_MODEL_21d288bd26b742188c4bf140dfd2e458",
              "IPY_MODEL_19475b0c66414555b587a9a825a8268c"
            ],
            "layout": "IPY_MODEL_50737bccfb384a43866f1383eef20618"
          }
        },
        "2c02a844c667469c937ba121fb71e84d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb63f40f1c0f455abf0af085e1fc61dd",
            "placeholder": "",
            "style": "IPY_MODEL_fa0bd68bf35e4d3194688de1a7935dc3",
            "value": " 990M/990M [01:10&lt;00:00, 15.4MB/s]"
          }
        },
        "31aecf641f4c4f9c994e2da8ab0951eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f2f207ae85a40c0aa32f8d218a70255",
            "placeholder": "",
            "style": "IPY_MODEL_0f7ae4cd186242c783429cb974531231",
            "value": " 287/287 [00:00&lt;00:00, 12.0kB/s]"
          }
        },
        "34c3b1a8055c47ea936113d26de06ab6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0ed9b3da1c7423e9cede7b758c5c06c",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4c22a13a55e143ceacda166d494631cc",
            "value": 231508
          }
        },
        "39e605366b044404b802f5a7fa615701": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d9655a157b447479fc6d5acb7d835e0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40f6ad0a394d4141ba2962410e4563fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "441b2fdb21a44ecc85e5d6533bcef753": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_814f6f7b1f6448559bcba07539d03b64",
            "max": 4563,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1bb1a8a8c3f24231877b4bccbc13f9ee",
            "value": 4563
          }
        },
        "464054529149475b8b1e74b24b28afae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "467317077d5e4c0c9ad9583f120b434b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2317f58d4faf4c4898083baf13b9f43c",
            "placeholder": "",
            "style": "IPY_MODEL_e629f37f938340629f33ae56ae0d18de",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "472c68127b0d4c8f93396aaac1b7f9f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4a8e6dede4064f6faa325066967d4429": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c22a13a55e143ceacda166d494631cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4d68c99f44df459b8e6f374fea704828": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4e65afefd4a249419b74fbc4473e5c0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0cddf0ee2fde4955948545b6548d021f",
            "max": 711396,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d12c06622560410b8af0f34ca4ca065d",
            "value": 711396
          }
        },
        "50737bccfb384a43866f1383eef20618": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50a6f34229fc40e6ad680332deba3062": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "537016e442064c1681f5bb812e119e95": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04d94de09a7447048ef4c48b3397cae5",
            "placeholder": "",
            "style": "IPY_MODEL_40f6ad0a394d4141ba2962410e4563fd",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "57c33c22ac124d99b263c990b5695433": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_537016e442064c1681f5bb812e119e95",
              "IPY_MODEL_20b4baa1531040f5bc5c0ff2b43a241c",
              "IPY_MODEL_1735a9f9df4149a098f02cf7257be709"
            ],
            "layout": "IPY_MODEL_3d9655a157b447479fc6d5acb7d835e0"
          }
        },
        "5c68e777dd734cc0bbb81d5162dd58ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_87f7dd9fb7e84a9f99ddaf5de46fe7d9",
              "IPY_MODEL_4e65afefd4a249419b74fbc4473e5c0e",
              "IPY_MODEL_9e05ca5c3ad54c1096ae932047c2f5b9"
            ],
            "layout": "IPY_MODEL_619379aa1c7643c699c249a768ae4162"
          }
        },
        "619379aa1c7643c699c249a768ae4162": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6310ba95b87f44fda20200fa501a59fe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63d3aae8ed5a4a0b9feaabbbd6b8e0bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "64b0fcb359994072acbff3ac0c5b7f14": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eca003d7b89c4189a83a249e3464dde0",
            "placeholder": "",
            "style": "IPY_MODEL_464054529149475b8b1e74b24b28afae",
            "value": " 232k/232k [00:00&lt;00:00, 1.22MB/s]"
          }
        },
        "6812e411ea92445483b26d363554757f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70d3a73dce5c4f7abc3b59efa51ab4c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94c4f51d230442aeb378fb874e2fcec5",
            "placeholder": "",
            "style": "IPY_MODEL_7bf8454bd5e24a4f9c8116b8f08cfe19",
            "value": "config.json: 100%"
          }
        },
        "771a083f78db46318a74582943f06499": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "779ef4c080bd4fff97d08bc2a9b8e5ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7b8a4297663048b48459460bdb567a61": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7bf8454bd5e24a4f9c8116b8f08cfe19": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "814f6f7b1f6448559bcba07539d03b64": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "860dc1e9cd5e4f7eba338a793d761825": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87f7dd9fb7e84a9f99ddaf5de46fe7d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1150c71179e44863af4efa90cddc56d3",
            "placeholder": "",
            "style": "IPY_MODEL_4d68c99f44df459b8e6f374fea704828",
            "value": "tokenizer.json: 100%"
          }
        },
        "8d9d9912947644dd9aa77b08ce25478c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39e605366b044404b802f5a7fa615701",
            "placeholder": "",
            "style": "IPY_MODEL_779ef4c080bd4fff97d08bc2a9b8e5ce",
            "value": "vocab.txt: 100%"
          }
        },
        "8e8bcbde84bc4867a2ccfeb59928747b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fa73acf518147b8998478d23fd000b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "94c4f51d230442aeb378fb874e2fcec5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98ce626cff4941bba945d890fce08369": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "99b8f6b62f2b4f7c81e90360a72d82ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6310ba95b87f44fda20200fa501a59fe",
            "max": 989820849,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1bb03ad1e1644edca469f318f18ce46b",
            "value": 989820849
          }
        },
        "9c0069b1dbf34d2cbc1f5622809df235": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e05ca5c3ad54c1096ae932047c2f5b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50a6f34229fc40e6ad680332deba3062",
            "placeholder": "",
            "style": "IPY_MODEL_be72f36e73834efca30cfe252ff2859d",
            "value": " 711k/711k [00:00&lt;00:00, 1.29MB/s]"
          }
        },
        "9f2f207ae85a40c0aa32f8d218a70255": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad583990677b4d1fb4d55843d6ae3b1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "afc01e8b61e04120b85de53b2afaa29d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b34dd15c42184d46bfac9aa28ee5b875": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8b7f960d70245599f27670784a655b9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be72f36e73834efca30cfe252ff2859d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c52e9a56c11c4dc4adf82f5493cd2824": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7aae1948ed14bcc8c176fd85e7e19da": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d12c06622560410b8af0f34ca4ca065d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "da835640583d4d19abae42a9f3c79256": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_afc01e8b61e04120b85de53b2afaa29d",
            "placeholder": "",
            "style": "IPY_MODEL_63d3aae8ed5a4a0b9feaabbbd6b8e0bf",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "dbf3969231824aafb5c5ea0a750733e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_16e9fd2e805c49da9a5038be60fb9d9d",
              "IPY_MODEL_05dc9528231e42a2b04f51d2ea883f4f",
              "IPY_MODEL_31aecf641f4c4f9c994e2da8ab0951eb"
            ],
            "layout": "IPY_MODEL_c7aae1948ed14bcc8c176fd85e7e19da"
          }
        },
        "e57a8ac878b7489e8bb9576a13170c3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e629f37f938340629f33ae56ae0d18de": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e7f2b76fe23c4e749221de97d54ffbc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c52e9a56c11c4dc4adf82f5493cd2824",
            "placeholder": "",
            "style": "IPY_MODEL_8fa73acf518147b8998478d23fd000b2",
            "value": " 4.56k/4.56k [00:00&lt;00:00, 104kB/s]"
          }
        },
        "eb63f40f1c0f455abf0af085e1fc61dd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eca003d7b89c4189a83a249e3464dde0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0ed9b3da1c7423e9cede7b758c5c06c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa0bd68bf35e4d3194688de1a7935dc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
